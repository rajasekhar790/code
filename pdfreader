import re
import requests
import pdfplumber

def extract_links_from_pdf(pdf_path):
    links = []
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            for url in re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text):
                if url.endswith('.pdf'):
                    links.append(url)
    return links

def download_pdf(url):
    response = requests.get(url)
    filename = url.split('/')[-1]
    with open(filename, 'wb') as f:
        f.write(response.content)
    return filename

def read_pdf_content(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        content = ''
        for page in pdf.pages:
            content += page.extract_text() + '\n'
    return content



import fitz  # PyMuPDF
import os

def extract_images_from_pdf(pdf_path, output_folder):
    # Ensure output folder exists
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    doc = fitz.open(pdf_path)
    image_count = 0

    for page_num in range(len(doc)):
        # Get the page
        page = doc.load_page(page_num)

        # List of images in the page
        image_list = page.get_images(full=True)

        # Save each image
        for image_index, img in enumerate(page.get_images(full=True)):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]

            # Construct the image file path
            image_filename = f"image{page_num+1}_{image_index+1}.png"
            image_path = os.path.join(output_folder, image_filename)

            with open(image_path, "wb") as image_file:
                image_file.write(image_bytes)

            image_count += 1

    doc.close()
    return image_count

# Example usage
pdf_path = 'path_to_your_pdf.pdf'
output_folder = 'extracted_images'
num_images = extract_images_from_pdf(pdf_path, output_folder)

print(f"Extracted {num_images} images.")



# Example Usage
pdf_path = 'your_pdf_file.pdf'
links = extract_links_from_pdf(pdf_path)

for link in links:
    linked_pdf = download_pdf(link)
    print(f"Content of {linked_pdf}:")
    print(read_pdf_content(linked_pdf))
